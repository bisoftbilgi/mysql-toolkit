input {
  file {
    path => ["${MYSQL_SLOW_LOG_PATH}"]
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/data/sincedb_mysql_slowquery"

    codec => multiline {
      pattern => "^# Time: "
      negate  => true
      what    => "previous"
    }
  }
}

filter {
  if ![path] and [log][file][path] {
    mutate { replace => { "path" => "%{[log][file][path]}" } }
  }

  # /logs/mysql-01/slow-query.log -> server_id=mysql-01
  dissect { mapping => { "path" => "/logs/%{server_id}/%{filename}" } }

  translate {
    field           => "server_id"
    destination     => "server_meta_json"
    dictionary_path => "/usr/share/logstash/extra/servers.yml"
    fallback        => "{\"cluster_name\":\"unknown\",\"server_name\":\"unknown\",\"server_ip\":\"0.0.0.0\"}"
  }

  json { source => "server_meta_json" target => "server_meta" }

  mutate {
    replace => {
      "cluster_name" => "%{[server_meta][cluster_name]}"
      "server_name"  => "%{[server_meta][server_name]}"
      "server_ip"    => "%{[server_meta][server_ip]}"
    }
    remove_field => ["server_meta_json","server_meta"]
  }


    # User@Host and Id parsing
    grok {
      match => {
        "message" => "# User@Host: %{USER:username}\[%{USER}\] @ %{DATA:client_host} \[%{IP:client_ip}?\]  Id: +%{NUMBER:session_id}"
      }
      add_field => {
        "[@metadata][parsed_user]" => "true"
      }
    }

    # Query_time and Lock_time parsing
    grok {
      match => {
        "message" => "# Query_time: %{NUMBER:query_time} +Lock_time: %{NUMBER:lock_time}"
      }
      add_field => {
        "[@metadata][parsed_metrics]" => "true"
      }
    }

    # SQL statement extraction
    grok {
      match => {
        "message" => "SET timestamp=%{NUMBER:timestamp}; NEWLINE (?<statement_text>.*?)(?:$| NEWLINE # Time:)"
      }
    }

    # Fallback if SET timestamp is missing
    if ![statement_text] {
      grok {
        match => {
          "message" => "Rows_examined: %{NUMBER} NEWLINE (?<statement_text>.*?)(?:$| NEWLINE # Time:)"
        }
      }
    }

    # Clean the statement
    if [statement_text] {
      mutate {
        gsub => [
          "statement_text", " NEWLINE ", "\n",
          "statement_text", "^\s+", "",
          "statement_text", "\s+$", ""
        ]
      }
    }

    # Convert Timestamp to ISO format
    if [log_time] {
      date {
        match => ["log_time", "ISO8601", "yyyy-MM-dd'T'HH:mm:ss.SSSSSS'Z'"]
        target => "log_time"
        timezone => "UTC"
      }
    }

    # Convert numeric fields
    mutate {
      convert => {
        "session_id" => "integer"
        "query_time" => "float"
        "lock_time" => "float"
      }
    }

    ##############################
    ## SERVER METADATA
    ##############################
    # Values are pulled from environment variables with defaults
    mutate {
      add_field => {
        "cluster_name" => "${CLUSTER_NAME:mysql-prod}"
        "server_name"  => "${SERVER_NAME:}"
        "server_ip"    => "${SERVER_IP:}"
        "application_name" => "mysql"
      }
    }
    
    # Dynamic hostname detection if env var is empty
    if [server_name] == "" {
      ruby {
        code => "
          require 'socket'
          event.set('server_name', Socket.gethostname)
        "
      }
    }
    
    # Dynamic IP detection if env var is empty
    if [server_ip] == "" {
      ruby {
        code => "
          require 'socket'
          ip = Socket.ip_address_list.detect { |i| i.ipv4_private? && !i.ipv4_loopback? }
          event.set('server_ip', ip.ip_address) if ip
        "
      }
    }

    # Default client IP handling
    if ![client_ip] or [client_ip] == "" {
      mutate {
        replace => { "client_ip" => "127.0.0.1" }
      }
    }

    # Cleanup
    mutate {
      remove_field => ["message", "host", "path", "@version", "timestamp", "client_host"]
    }

    # Validation
    if ![@metadata][parsed_time] or ![@metadata][parsed_metrics] {
      drop { }
    }
  }
}

output {
  if "mysql_slowquery" in [tags] {
    
    # Write to PostgreSQL using Environment Variables
    jdbc {
      driver_class => "org.postgresql.Driver"
      # Connection string built from env vars
      connection_string => "jdbc:postgresql://${PG_HOST}:${PG_PORT}/${PG_DB_NAME}"
      username => "${PG_USER}"
      password => "${PG_PASSWORD}"
      statement => [
        "INSERT INTO ${PG_TABLE_NAME:mysql_slowquery_logs} (log_time, username, client_ip, session_id, query_time, lock_time, statement_text, cluster_name, server_name, server_ip, application_name) VALUES (?::timestamptz, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
        "log_time", "username", "client_ip", "session_id", "query_time", "lock_time", "statement_text", "cluster_name", "server_name", "server_ip", "application_name"
      ]
    }

   } 
  stdout { codec => rubydebug }
}
